@article{Koenker1978,
         abstract = {A simple minimization problem yielding the ordinary sample quantiles in the location model is shown to generalize naturally to the linear model generating a new class of statistics we term "regression quantiles." The estimator which minimizes the sum of absolute residuals is an important special case. Some equivariance properties and the joint asymptotic distribution of regression quantiles are established. These results permit a natural generalization to the linear model of certain well-known robust estimators of location. Estimators are suggested, which have comparable efficiency to least squares for Gaussian linear models while substantially out-performing the least-squares estimator over a wide class of non-Gaussian error distributions.},
         author = {Koenker, Roger and Bassett, Gilbert and Jan, No},
         journal = {Econometrica},
         number = {1},
         pages = {33--50},
         title = {{Regression Quantiles}},
         volume = {46},
         year = {1978}
}
@book{Davino2014,
      author = {Davino, Cristina and Furno, Marilena and Vistocco, Domenico},
      file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Davino et al - Quantile Regression.pdf:pdf},
      isbn = {9781626239777},
      title = {{Quantile Regression: Theory and Applications}},
      year = {2014}
}
@article{Galvao2013,
         abstract = {This article studies quantile regression in an autoregressive dynamic framework with exogenous stationary covariates. We demonstrate the potential of the quantile autoregressive distributed lag model with an application to house price returns in the United Kingdom. The results show that house price returns present a heterogeneous autoregressive behaviour across the quantiles. Real GDP growth and interest rates also have an asymmetric impact on house prices variations. {\textcopyright} Blackwell Publishing Ltd and the Department of Economics, University of Oxford 2011.},
         author = {Galvao, Antonio F. and Montes-Rojas, Gabriel and Park, Sung Y.},
         doi = {10.1111/j.1468-0084.2011.00683.x},
         file = {:Users/taisbellini/Downloads/Galvao Montes-Rojas Park OBES 2013.pdf:pdf},
         issn = {03059049},
         journal = {Oxford Bulletin of Economics and Statistics},
         number = {2},
         pages = {307--321},
         title = {{Quantile Autoregressive Distributed Lag Model with an Application to House Price Returns}},
         volume = {75},
         year = {2013}
}
@article{Sottile2020,
         abstract = {The coefficients of a quantile regression model are one-to-one functions of the order of the quantile. In standard quantile regression (QR), different quantiles are estimated one at a time. Another possibility is to model the coefficient functions parametrically, an approach that is referred to as quantile regression coefficients modeling (QRCM). Compared with standard QR, the QRCM approach facilitates estimation, inference and interpretation of the results, and generates more efficient estimators. We designed a penalized method that can address the selection of covariates in this particular modelling framework. Unlike standard penalized quantile regression estimators, in which model selection is quantile-specific, our approach permits using information on all quantiles simultaneously. We describe the estimator, provide simulation results and analyse the data that motivated the present article. The proposed approach is implemented in the qrcmNP package in R.},
         author = {Sottile, Gianluca and Frumento, Paolo and Chiodi, Marcello and Bottai, Matteo},
         doi = {10.1177/1471082X19825523},
         file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Sottile 2020 StatMod.pdf:pdf},
         issn = {14770342},
         journal = {Statistical Modelling},
         keywords = {Lasso penalty,Penalized integrated loss minimization (PILM),inspiratory capacity,penalized quantile regression coefficients modelli,tuning parameter selection},
         number = {4},
         pages = {369--385},
         title = {{A penalized approach to covariate selection through quantile regression coefficient models}},
         volume = {20},
         year = {2020}
}
@book{Koenker2005,
abstract = {Quantile regression robustly estimates the typical and extreme values of a response.},
author = {Koenker, Roger},
doi = {10.1038/s41592-019-0406-y},
isbn = {9780521845731},
issn = {15487105},
pages = {368},
pmid = {31147637},
title = {{Quantile regression}},
year = {2005}
}
@article{Konzen2016,
abstract = {This paper studies some forms of LASSO-type penalties in time series to reduce the dimensionality of the parameter space as well as to improve out-of-sample forecasting performance. In particular, we propose a method that we call WLadaLASSO (weighted lag adaptive LASSO), which assigns not only different weights to each coefficient but also further penalizes coefficients of higher-lagged covariates. In our Monte Carlo implementation, the WLadaLASSO is superior in terms of covariate selection, parameter estimation precision and forecasting, when compared to both LASSO and adaLASSO, especially for a higher number of candidate lags and a stronger linear dependence between predictors. Empirical studies illustrate our approach for US risk premium and US inflation forecasting with good results. Copyright {\textcopyright} 2016 John Wiley & Sons, Ltd.},
author = {Konzen, Evandro and Ziegelmann, Flavio A.},
doi = {10.1002/for.2403},
file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Konzen_Ziegelmann(2016)JoF_final.pdf:pdf},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {LASSO,adaLASSO,forecasting,time series,variable selection},
number = {7},
pages = {592--612},
title = {{LASSO-Type Penalties for Covariate Selection and Forecasting in Time Series}},
volume = {35},
year = {2016}
}
@book{Koenker2018,
author = {Koenker, Roger and Chernozhukov, Victor and He, Xuming and Peng, Limin},
file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Koenker, Chernozhukov, He, Peng - Handbook of Quantile Regression.pdf:pdf},
title = {{Handbook of Quantile Regression}},
year = {2018}
}
@article{Koenker2006,
abstract = {We consider quantile autoregression (QAR) models in which the autoregressive coefficients can he expressed as monotone functions of a single, scalar random variable. The models can capture systematic influences of conditioning variables on the location, scale, and shape of the conditional distribution of the response, and thus constitute a significant extension of classical constant coefficient linear time series models in which the effect of conditioning is confined to a location shift. The models may be interpreted as a special case of the general random-coefficient autoregression model with strongly dependent coefficients. Statistical properties of the proposed model and associated estimators are studied. The limiting distributions of the autoregression quantile process are derived. QAR inference methods are also investigated. Empirical applications of the model to the U.S. unemployment rate, short-term interest rate, and gasoline prices highlight the model's potential. {\textcopyright} 2006 American Statistical Association.},
author = {Koenker, Roger and Xiao, Zhijie},
doi = {10.1198/016214506000000672},
file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Koenker Xiao 2006 JASA.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Asymmetric persistence,Autoregression,Comonotonicity,Quantile,Random coefficients},
number = {475},
pages = {980--990},
title = {{Quantile autoregression}},
volume = {101},
year = {2006}
}
@article{Frumento2016,
abstract = {Summary Estimating the conditional quantiles of outcome variables of interest is frequent in many research areas, and quantile regression is foremost among the utilized methods. The coefficients of a quantile regression model depend on the order of the quantile being estimated. For example, the coefficients for the median are generally different from those of the 10th centile. In this article, we describe an approach to modeling the regression coefficients as parametric functions of the order of the quantile. This approach may have advantages in terms of parsimony, efficiency, and may expand the potential of statistical modeling. Goodness-of-fit measures and testing procedures are discussed, and the results of a simulation study are presented. We apply the method to analyze the data that motivated this work. The described method is implemented in the qrcm R package.},
author = {Frumento, Paolo and Bottai, Matteo},
doi = {https://doi.org/10.1111/biom.12410},
journal = {Biometrics},
keywords = { Integrated loss minimization (ILM), Quantile regression coefficients modeling (QRCM),Inspiratory capacity},
number = {1},
pages = {74--84},
title = {{Parametric modeling of quantile regression coefficient functions}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12410},
volume = {72},
year = {2016}
}

@article{Zou2006,
author = {Zou, Hui},
doi = {10.1198/016214506000000735},
file = {:Users/taisbellini/Downloads/adalasso.pdf:pdf},
keywords = {asymptotic normality,lasso,minimax,oracle inequality,oracle procedure,variable selection},
number = {476},
pages = {1418--1429},
title = {{The Adaptive Lasso and Its Oracle Properties}},
volume = {101},
year = {2006}
}
@misc{Horta2021,
  author = {Horta, Eduardo},
  title = {Quantile Regression: Facts and digressions},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eduardohorta/QuantRegFacts}},
  commit = {4fe5d543530b15c006ec31bdb113c2aa0b9348b9}
}

@article{Yuan2006,
abstract = {We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multifactor analysis-of-variance problem as the most important and well-known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non-negative garrotte for factor selection. The lasso, the LARS algorithm and the non-negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods. {\textcopyright} 2006 Royal Statistical Society.},
author = {Yuan, Ming and Lin, Yi},
doi = {10.1111/j.1467-9868.2005.00532.x},
file = {:Users/taisbellini/workspace/dissertacao-estudos/quantile-regression/Yuan-Lin-2006-RoyStatSocB.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Analysis of variance,Lasso,Least angle regression,Non-negative garrotte,Piecewise linear solution path},
number = {1},
pages = {49--67},
title = {{Model selection and estimation in regression with grouped variables}},
volume = {68},
year = {2006}
}


@Article{cvxr2020,
    title = {{CVXR}: An {R} Package for Disciplined Convex Optimization},
    author = {Anqi Fu and Balasubramanian Narasimhan and Stephen Boyd},
    journal = {Journal of Statistical Software},
    year = {2020},
    volume = {94},
    number = {14},
    pages = {1--34},
    doi = {10.18637/jss.v094.i14},
  }




