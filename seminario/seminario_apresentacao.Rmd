---
title: "Neural Network Predictive Modeling on Dynamic Portfolio Management"
subtitle: "Yu, Jiayang and Chang, Kuo-Chu"
author: "Gustavo Alovisi and Tais Bellini"
date: "April, 2021"
output: 
  beamer_presentation:
    slide_level: 2
    theme: "Boadilla"
header-includes:
  - \AtBeginDocument{\title[Seminário - Séries Temporais - Verão 2021]{Neural Network Predictive Modeling on Dynamic Portfolio Management}}
bibliography: ref.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

## Motivation

- Use modern machine learning techniques to build on well established macroeconomics factors literature with respect to asset price prediction.

- The main goal is to use macroeconomics factors to build an optimal asset portfolio of indexes that protects against extreme losses (left tail returns) while still offering adequate returns.

## Proposal

- Framework for portfolio optimization:

![High level diagram of the proposal. (Authors)](img/ProposalSeminario.png){width=90%}


# Fundamentals

## GARCH

- In order to model each univariate macroeconomic factor volatility, a GARCH(1,1) model is proposed. 

- Volatility is modeled using a GARCH(1,1) because the majority of financial assets share common 'stylized facts':
  - Heavy Tails: the distribution of returns usually shows heavier tails than Normal or t distribution: extreme losses or gains aren't that rare. 
  - Gain/Loss Asymmetry: large downturn in assets prices do not necessarily reflect equally large upturns. 
  - Volatility Clustering: high volatility events tends to cluster over time. Economic crisis. 
- Thus, using simple asset's standard deviation as a risk measure can be problematic.

## Pair Copula and Dependence Modeling

- GARCH(1,1) model is able to capture univariate volatility. However, it is well known that dependence between financial assets exist.
- During crisis, financial assets exhibits different dependence structures with respect to normal or bullish market conditions: they tend to have a very correlated loss dynamic. 
- Copula-GARCH models are able to capture the multivariate assets dependence while multivariate probability function estimation is not needed. 

## More about copula

- The main advantage of using copulas is that it allows separating the marginal assets distribution (here modeled using GARCH) from the dependence structure. Then, different dependence behaviors can be captured by different copula functions. 

\begin{theorem}
Let $F$ be an n-dimensional distribution function with margins $F_1,...F_n$. Then there exists an n-copula $C$ such that for all $y \in R^n$, \begin{equation}
F(y_1,...,y_n) = C(F_1(y_1),...,F_n(y_n)).
\end{equation} Furthermore, if $F_1,...F_n$ are continuous, then $C$ is unique.
\end{theorem}

## More about copula
\begin{corollary}
Let $f$ be the multivariate probability density function the probability distribution $F$ and $f_1,...,f_n$ the univariate probability density functions of the margins $F_1,...,F_n$. The copulas density function of an n-copula $C$ is the function c: $U[0,1]^n \mapsto [0,\infty)$ such that \begin{equation}
      c(u_1,...,u_n)= \frac{\partial^n C(u_1,...,u_n)}{\partial u_1,...,\partial u_n} =                \frac{f(y_1,...,y_n)}{\prod^{n}_{i=1}f_i(y_i)}.
\end{equation}
\end{corollary}

## How this all connects

Using theorems above, the conditional joint distribution can be decomposed, given previous information set, into conditional marginal distributions and conditional copulas. For $t \in (1,...,T)$ let $Y_t|I_{t-1} \sim F(.|I_{t-1})$ and $Y_{i,t}|I_{t-1} \sim F_i(.|I_{t-1})$, then \begin{equation}
F(y|I_{t-1}) = C(F_1(y_1|I_{t-1}),..., F_n(y_n|I_{t-1})|I_{t-1})
\end{equation}

Then, from the GARCH(1,1) model, we incorporate equation (VER) to the multivariate copula and the white-noise term ${z_t}$ can be derived from the copula structure: \begin{equation}
z_t|I_{t-1} \sim F_{z,t} = C_t(F_{1,t}, ... , F_{n,t}) \end{equation} where $z_t$ can then be estimated from \begin{equation}
\frac{R_t - \mu}{\sigma_t|I_{t-1}} \end{equation}

## Pair Copula (PCC)

- Different copula functions captures different kinds of dependence. 
- t-copula is symmetrical and captures both upper and lower tail dependence. Clayton copula captures lower tail, etc. 
- Computation requirements to estimate multivariate copula parameters increases with dimension of time-series. 
- However, multivariate joint density can be written as a product of pair copula on different conditional distributions.
- Copula parameters are then estimated with log-likelihood optimization along de layers of pair copula trees. 
- Final model is the one that optimizes AIC. 

## Neural Networks

- The advantage of using deep neural networks for financial forecasting, as opposed to linear models such as ARIMA, is that they can approximate the relationship between input data and predicted outputs, even in highly complex and correlated scenarios. 

- Most of the studies with neural network use the historical data of the financial assets to explore the hidden relationship between them.

## The Economic Factor-Based Predictive Model (EFPM) {.allowframebreaks}

- This proposal uses neural networks to explore the relationships between macroeconomic factors and financial assets returns.

- A feedforward neural network with one hidden layer and one output layer that takes the simulation of 11 major macroeconomic factors as input and produces the return of 6 vehicle investment assets.
 
- The network maps the input to the output using the function below, where $\phi$ is the sigmoid function $\left(\frac{e^x}{1+e^x}\right)$ and $\alpha$ is a bias term:

$$\hat{y_i} = \phi_{output}\left(\alpha_1 + \sum_{k \rightarrow output}{w_{k,output}\phi\left(\alpha_k+\sum_{j \rightarrow k}w_{jk}x_{ij}\right)}\right)$$

- Find the optimal weights $w_{k,output}$ and $w_{jk}$ minimizing the SSE using gradient descent to iteractively update $w_{jk} \rightarrow w_{jk} - \eta\frac{\partial SSE}{\partial w_{jk}}$ where $\eta$ is the learning rate that controls the size of the step. 

![Sample of trained neural network. @Yu2020](img/neural_network.png){width=80%}

## Mean CVaR

- Traditional portfolio optimization follows Markowitz mean-variance model. 
- As mentioned earlier, there's a need to model lower tail risk. New risk measures introduced. 
- VaR (Value at Risk): VaR is defined as $VaR_{\beta}(w) = min(l \in R: \psi(w,l) \ge \beta)$. It can be interpreted as the loss at the $\beta$ percentile. However, VaR has some limitations (not coherent, difficult to apply in a portfolio optimization problem). 
- CVaR (Conditional Value at Risk): CVaR is defined as \begin{equation} CVaR_\beta(w) = \frac{1}{1-\beta}\int_{f(w,y)\ge VaR_{\beta(w)}}f(w,y)p(y)dy, \end{equation} where $y$ represents returns with density $p(y)$ and $f(w,y)$ is a loss function. It can be interpreted as the mean loss from VaR to $-\infty$. 
- CVaR is a coherent risk measure and the optimization w.r.t to a portfolio is well defined and easier to be done. 

## Mean-CVaR portfolio optimization

- An easier discretized version function can be used to calculate $CVaR_\beta$ approximating the integral above: \begin{equation}
F_\beta(w,l) = l + \frac{1}{q(1+\beta)}\sum^{q}_{k = 1}[f(w, y_k)-l]^{+}.\end{equation} Minimizing CVaR is thus the equivalent of minimizing $F_\beta(w,l)$. The final mean-CVaR portfolio optimization is then defined as: 
\begin{equation}
min_{w \in W} F_\beta(w,l) = l + \frac{1}{q(1+\beta)}\sum^{q}_{k = 1}S_k 
s.t. S_k \ge f(w, y_k) - l = -w^Ty_k - l 
S_k \ge 0
\sum^{N}_{i=1}w_i = 1
w^Ty \ge \mu_0
\end{equation} where $S_k$ is an auxiliary term to approximate $[f(w,y_k)-l]^+$ so that the optimization can be solved as a Linear Programming problem (Simplex or Interior Point).

# Methodology

## Neural Net-Based Pair Copula GARCH Portfolio Optimization Framework

![Process workflow diagram. @Yu2020](img/workflow.png){width=70%}

## Data Collection {.allowframebreaks}

- 6 Vanguard index mutual funds

Table: Investment Instruments. @Yu2020

  Security Name                         Security Symbol
-----------------                   ----------------------
 Vanguard 500 Index                          VFINX
 Vanguard Small Cap Index                    NAESX
 Vanguard Total Intl Stock Index             VGTSX
 Vanguard Emerging Mkts Stock Index          VEIEX
 Vanguard Total Bond Market Index            VBMFX
 Vanguard Real Estate Index                  VGSLX

- 11 macroeconomic factors

![Table of macroeconomic factors. @Yu2020](img/macroeconomic_variables.png){width=90%}

## Training

- Training period of 60-month interval to get the optimal weight and test out-of-sample data for the following month. Training and testing repeated starting on January 2002 until all data points in sample are evaluated.
- Min–max normalization method on both the monthly log returns of the index funds and the monthly log-percentage change of the macroeconomic variables to accelerate gradient descent algorithm. Data set also normalized.
- 60-month data set split into one training set of 54 data points to form the model, and the remaining 6-month data that is used to tune the hyperparameter, such as number of neurons in the hidden layer. 
- Mean squared error (MSE) of predicted output minimized to select the best network structure.

## Simulation 

- Simulate 5000 log-percentage change of economic variables using the the pair copula-GARCH(1,1) model.
- Use the 5000 simulated log-percentage change of the variables as input for the neural network model and get the 5000 simulated log-percentage returns of investment assets.
- 154 months of sample returns.
- Use the simulated return series of past 60 months as input for the Mean-CVar optimization and get the optimal weights of the portfolio for the next month.
   - confidence level ($\beta$): 99%
   - expected return parameter ($\mu_0$): minimum of 10% of annualized return and average return of past 60 months of assets
   
## Validation

- Portfolio performance for the one-month period is recorded, and the process is repeated the next month using the previous 60 months data again.
- Range from February 2007 to November 2009.
- $1000 invested at the end of January 2007.

## Benchmarking

- The proposed strategy is compared to 3 methods:
   - Equally weighted (EW): index funds in the portfolio are simply allocated equally and rebalanced to equal weights each month.
   - Historical return-based (HRB): historical returns of the index funds are computed directly as inputs to the Mean-CVaR framework (no simulation).
   - Direct simulation (DS): monthly returns of the index funds are simulated by applying historical data into the pair copula-GARCH framework without utilizing the neural network framework and information from economic variables.

# Results

## References {.allowframebreaks}
